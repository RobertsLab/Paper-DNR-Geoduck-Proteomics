{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook I will run PECAN on the DIA data .mzML files. \n",
    "\n",
    "## _Important note!: PECAN is extremely memory intensive. Prior to running all, consider only running one or two files to assess necessary time and results. Also, don't run unecessary files, e.g. data from blanks_  \n",
    "\n",
    "### Let's review. Prior to executing we've done the following:\n",
    "  * Converted the .raw files that are produced by Lumos to .mzML using MSConvert\n",
    "  * Obtained a background proteome file from the geoduck gonad transcriptome, a protein fasta file (provided by Steven)\n",
    "  * Obtained the PRTC protein sequence fasta file and merged with the proteome fasta file\n",
    "  * Trypsin digested the proteome+PRTC file in silico using Protein Digestion Simulator\n",
    "  * Obtained the isolation scheme file (from Emma) and converted to .csv  \n",
    "  * Created a .txt file with list of paths to all mzML files   \n",
    "  * Confired that we have a a .txt file with path to the background proteome database "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All PECAN input files must be located in the same directory. Let's move them to the same directory now: \n",
    "\n",
    "[NEED TO INCLUDE SCRIPT TO DO THIS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final PECAN execution was run by UW Genome Sciences due to the enormous amount of memory required.  However, in the interest of potential future users (e.g. using Hyak), here are some lessons learned while using PECAN. Note, these may be fixed in future updates: \n",
    "  * The `-b` command that tells PECAN to override the default background proteome wasn't working, so Sean Bennett added my background proteome file to the Pecan configure file as a species called \"LAURAGEO\"\n",
    "  * Sean also did some background re-configuring in Emu/Pecan. See his [notebook entry](https://genefish.wordpress.com/2017/02/24/more-proteomics-software-fun/). \n",
    "  * The .txt file that provides all the mzML file paths assumes that the mzML files are located in the **same** parent directories, so you must not include all the parent directories in the file paths (it gets confused).  So, all file paths in my .txt files were simpified, and one directory was created housing all files pertinent to the Pecan run. \n",
    "  * The Percolator function was not working when we ran PECAN, so Sean developed a work-around, included at the end of this notebook. Be sure to review that if you are having trouble generating a .blib file. \n",
    "  \n",
    "### Let's look at the input files that I made: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/shlaura3/Documents/Roberts Lab/DNR_Geoduck/Documentation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-19_Geoduck-database4pecan.tabular\r\n",
      "DNR_Geoduck_DatabasePath.txt\r\n",
      "DNR_Geoduck_IsolationScheme.csv\r\n",
      "DNR_Geoduck_mzMLpath.txt\r\n",
      "P00000_Pierce_prtc.fasta\r\n",
      "Pierce_PRTC.tabular\r\n"
     ]
    }
   ],
   "source": [
    "ls ../Analyses/Pecan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-02-19_Geoduck-database4pecan.tabular\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../Analyses/Pecan/DNR_Geoduck_DatabasePath.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455.456911\t465.461459\r\n",
      "465.461459\t475.466006\r\n",
      "475.466006\t485.470554\r\n",
      "485.470554\t495.475101\r\n",
      "495.475101\t505.479649\r\n",
      "505.479649\t515.484196\r\n",
      "515.484196\t525.488744\r\n",
      "525.488744\t535.493291\r\n",
      "535.493291\t545.497839\r\n",
      "545.497839\t555.502386\r\n",
      "555.502386\t565.506934\r\n",
      "565.506934\t575.511481\r\n",
      "575.511481\t585.516029\r\n",
      "585.516029\t595.520576\r\n",
      "595.520576\t605.525124\r\n",
      "605.525124\t615.529671\r\n",
      "615.529671\t625.534219\r\n",
      "625.534219\t635.538766\r\n",
      "635.538766\t645.543314\r\n",
      "645.543314\t655.547861\r\n",
      "655.547861\t665.552409\r\n",
      "665.552409\t675.556956\r\n",
      "675.556956\t685.561504\r\n",
      "685.561504\t695.566051\r\n",
      "695.566051\t705.570599\r\n",
      "705.570599\t715.575146\r\n",
      "715.575146\t725.579694\r\n",
      "725.579694\t735.584241\r\n",
      "735.584241\t745.588789\r\n",
      "745.588789\t755.593336\r\n",
      "755.593336\t765.597884\r\n",
      "765.597884\t775.602431\r\n",
      "775.602431\t785.606979\r\n",
      "785.606979\t795.611526\r\n",
      "795.611526\t805.616074\r\n",
      "805.616074\t815.620621\r\n",
      "815.620621\t825.625169\r\n",
      "825.625169\t835.629716\r\n",
      "835.629716\t845.634264\r\n",
      "845.634264\t855.638811\r\n",
      "450.454638\t460.459185\r\n",
      "460.459185\t470.463732\r\n",
      "470.463732\t480.46828\r\n",
      "480.46828\t490.472827\r\n",
      "490.472827\t500.477375\r\n",
      "500.477375\t510.481922\r\n",
      "510.481922\t520.48647\r\n",
      "520.48647\t530.491017\r\n",
      "530.491017\t540.495565\r\n",
      "540.495565\t550.500112\r\n",
      "550.500112\t560.50466\r\n",
      "560.50466\t570.509207\r\n",
      "570.509207\t580.513755\r\n",
      "580.513755\t590.518302\r\n",
      "590.518302\t600.52285\r\n",
      "600.52285\t610.527397\r\n",
      "610.527397\t620.531945\r\n",
      "620.531945\t630.536492\r\n",
      "630.536492\t640.54104\r\n",
      "640.54104\t650.545587\r\n",
      "650.545587\t660.550135\r\n",
      "660.550135\t670.554682\r\n",
      "670.554682\t680.55923\r\n",
      "680.55923\t690.563777\r\n",
      "690.563777\t700.568325\r\n",
      "700.568325\t710.572872\r\n",
      "710.572872\t720.57742\r\n",
      "720.57742\t730.581967\r\n",
      "730.581967\t740.586515\r\n",
      "740.586515\t750.591062\r\n",
      "750.591062\t760.59561\r\n",
      "760.59561\t770.600157\r\n",
      "770.600157\t780.604705\r\n",
      "780.604705\t790.609252\r\n",
      "790.609252\t800.6138\r\n",
      "800.6138\t810.618347\r\n",
      "810.618347\t820.622895\r\n",
      "820.622895\t830.627442\r\n",
      "830.627442\t840.63199\r\n",
      "840.63199\t850.636537\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../Analyses/Pecan/DNR_Geoduck_IsolationScheme.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017_January_23_envtstress_blank10.mzML\r\n",
      "2017_January_23_envtstress_blank11.mzML\r\n",
      "2017_January_23_envtstress_blank12.mzML\r\n",
      "2017_January_23_envtstress_blank13.mzML\r\n",
      "2017_January_23_envtstress_blank14.mzML\r\n",
      "2017_January_23_envtstress_blank15.mzML\r\n",
      "2017_January_23_envtstress_blank16.mzML\r\n",
      "2017_January_23_envtstress_blank18.mzML\r\n",
      "2017_January_23_envtstress_blank19.mzML\r\n",
      "2017_January_23_envtstress_blank1.mzML\r\n",
      "2017_January_23_envtstress_blank20.mzML\r\n",
      "2017_January_23_envtstress_blank21_170126134757.mzML\r\n",
      "2017_January_23_envtstress_blank21.mzML\r\n",
      "2017_January_23_envtstress_blank2_2.mzML\r\n",
      "2017_January_23_envtstress_blank22.mzML\r\n",
      "2017_January_23_envtstress_blank23.mzML\r\n",
      "2017_January_23_envtstress_blank24.mzML\r\n",
      "2017_January_23_envtstress_blank2.mzML\r\n",
      "2017_January_23_envtstress_blank3.mzML\r\n",
      "2017_January_23_envtstress_blank4.mzML\r\n",
      "2017_January_23_envtstress_blank5.mzML\r\n",
      "2017_January_23_envtstress_blank6.mzML\r\n",
      "2017_January_23_envtstress_blank7_170124182434.mzML\r\n",
      "2017_January_23_envtstress_blank7.mzML\r\n",
      "2017_January_23_envtstress_blank8_170124213729.mzML\r\n",
      "2017_January_23_envtstress_blank8.mzML\r\n",
      "2017_January_23_envtstress_blank9.mzML\r\n",
      "2017_January_23_envtstress_geoduck10.mzML\r\n",
      "2017_January_23_envtstress_geoduck11.mzML\r\n",
      "2017_January_23_envtstress_geoduck12.mzML\r\n",
      "2017_January_23_envtstress_geoduck13.mzML\r\n",
      "2017_January_23_envtstress_geoduck14.mzML\r\n",
      "2017_January_23_envtstress_geoduck15.mzML\r\n",
      "2017_January_23_envtstress_geoduck17.mzML\r\n",
      "2017_January_23_envtstress_geoduck18.mzML\r\n",
      "2017_January_23_envtstress_geoduck19.mzML\r\n",
      "2017_January_23_envtstress_geoduck1.mzML\r\n",
      "2017_January_23_envtstress_geoduck20.mzML\r\n",
      "2017_January_23_envtstress_geoduck2.mzML\r\n",
      "2017_January_23_envtstress_geoduck3.mzML\r\n",
      "2017_January_23_envtstress_geoduck4.mzML\r\n",
      "2017_January_23_envtstress_geoduck5.mzML\r\n",
      "2017_January_23_envtstress_geoduck6.mzML\r\n",
      "2017_January_23_envtstress_geoduck7_170124190430.mzML\r\n",
      "2017_January_23_envtstress_geoduck7.mzML\r\n",
      "2017_January_23_envtstress_geoduck8.mzML\r\n",
      "2017_January_23_envtstress_geoduck9.mzML\r\n"
     ]
    }
   ],
   "source": [
    "! cat ../Analyses/Pecan/DNR_Geoduck_mzMLpath.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Below is the final Pecan script. Here are some definitions/explanations of the inputs\n",
    "\n",
    "  * `-o` Output directory  \n",
    "  * `-s LAURAGEO` Database used (my digested proteome was added to the .config file and named \"LAURAGEO\", since the `-b` override didn't work).  \n",
    "  * `-n` the name of my output .blib file; no need to include a .blib file ending  \n",
    "  * `--isolationSchemeType BOARDER` I used BOARDER because my isolation scheme format is ranges of m/z (2 columns). Note: BOARDER is spelled wrong (should be BORDER), but that's how Pecan spells it  \n",
    "  * `--pecanMemRequest 48` We tried 16 but Pecan requested 94. The max Emu allows for is 48, so that's the best we can do.   \n",
    "  * Need to specify the mzMLpath.txt, DatabasePath.txt, and IsolationScheme.csv files in that order  \n",
    "  * `--fido`  Not exactly sure what this does; from the [Evernote Tutorial](https://www.evernote.com/shard/s347/sh/edcb06ab-d008-418f-b28f-52f6614f1c39/2984ab55f427fcfe) the command tells Pecan to \"Include protein inference using FIDO in percolator\"  \n",
    "  * `--jointPercolator` Include Percolator step in the Pecan run.  \n",
    "  \n",
    "NOTE: I do not recommend executing the below commands through Jupyter Notebook since PECAN is a processor/memory intensive program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up Pecan directories\n",
    "pecanpie -o /home/srlab/Documents/Laura/DNR_geoduck/Pecan3 \\\n",
    "-s LAURAGEO \\\n",
    "-n DNR_geoduck_SpLibrary --isolationSchemeType BOARDER \\\n",
    "--pecanMemRequest 48 \\\n",
    "/home/srlab/Documents/Laura/DNR_geoduck/DNR_Geoduck_mzMLpath.txt \\\n",
    "/home/srlab/Documents/Laura/DNR_geoduck/DNR_Geoduck_DatabasePath.txt \\\n",
    "/home/srlab/Documents/Laura/DNR_geoduck/DNR_Geoduck_IsolationScheme.csv \\\n",
    "--fido --jointPercolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Then, execute the command\n",
    "cd /home/srlab/Documents/Laura/DNR_geoduck/Pecan3 \\\n",
    "./run_search.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### In the version of PECAN that Sean & I were using Percolator did not execute, so we needed to force it to.  Percolator is a function that \"integrates\" results from PECAN and builds a .blib file. The following are instructions from Sean that were used to \"hack\" a .blib file:\n",
    "\n",
    "Overall, run the: \n",
    "  /geoduck.job file to aggregate all the separate isolation window results, then...\n",
    "  /percolator.job file to aggregate all the samples, then..\n",
    "  /pecan2blig.job file to condense everything into one .blib file. \n",
    "  \n",
    "  * Step 1) Go to Pecan output directory\n",
    "  * Step 2) Under \"Percolatorr\" directory there's a series of job files; take the first geoduck job file, and execute: `chmod +x [jobfilename]` This tells Linux that it's an executable file, and run that.\n",
    "  * Step 3) Execute `./[jobfilename]`  \n",
    "  * Step 4) Back out of the percolator director, and go to the pecan2blib directory\n",
    "  * Step 5) Execute the same `chmod +x [jobfilename]` in the pecan2blib directory\n",
    "  \n",
    "**ALSO**: in all the percolator sample.job and joint.job files have the -Q input. If the error log shows that it doesn't know what -Q is, remove it from all the job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
